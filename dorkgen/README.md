# Dork URL Crawler (dorkgen)

## üìù –û–ø–∏—Å–∞–Ω–∏–µ

–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –≤–µ–±-–∫—Ä–∞—É–ª–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Ç–æ–ª—å–∫–æ —Å–æ–±–∏—Ä–∞–µ—Ç URL, –Ω–æ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç email-–∞–¥—Ä–µ—Å–∞ –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ HTML. –ò–¥–µ–∞–ª–µ–Ω –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ—Ä–∫–æ–≤ –∏ —Å–±–æ—Ä–∞ –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å —Å–∞–π—Ç–∞.

## üéØ –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

- –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ–±-—Å–∞–π—Ç–∞
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö URL (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –∏ –≤–Ω–µ—à–Ω–∏—Ö)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä email-–∞–¥—Ä–µ—Å–æ–≤
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–æ—Ä–∫–æ–≤
- –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç—ã —Å–∞–π—Ç–∞ —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏

## üìã –§–∞–π–ª—ã

- **`spider.py`** - –û—Å–Ω–æ–≤–Ω–æ–π –∫—Ä–∞—É–ª–µ—Ä
- **`tururu.py`** - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç
- **`base.txt`** - –ë–∞–∑–æ–≤—ã–µ URL –¥–ª—è —Å—Ç–∞—Ä—Ç–∞
- **`temp0`** - –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ HTML
- **`output/`** - –ü–∞–ø–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
  - `urls.txt` - –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ URL
  - `emails.txt` - –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ email/–∏–º–µ–Ω–∞

## üîß –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

```bash
pip install requests
```

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ó–∞–ø—É—Å–∫

```bash
python spider.py
```

### –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤–≤–æ–¥

```
Input site
http://www.fa.ru/Pages/Home.aspx
```

## üìä –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç

### 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
```python
site = 'http://www.fa.ru/Pages/Home.aspx'
site00 = site.split('/')[2].split('.')[-2]  # –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω: 'fa'
```

### 2. –ü–µ—Ä–≤–∏—á–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
- –°–∫–∞—á–∏–≤–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
- –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ —Å—Å—ã–ª–∫–∏
- –ò—â–µ—Ç email –≤ –∞—Ç—Ä–∏–±—É—Ç–∞—Ö `name`

### 3. –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥
```python
def check(temp1_save, sites_score, site, count, count2, dork_score):
    for x in range(len(sites_score)):
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–∂–¥—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π URL
        # –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏ –∏ email
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç
```

### 4. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
- –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∫ —Ç–æ–º—É –∂–µ –¥–æ–º–µ–Ω—É
- –§–∏–ª—å—Ç—Ä—É–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã
- –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏

### 5. –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
```python
print str(len(sites_score)) + str([count]) + str([count2])
# [–í—Å–µ–≥–æ URL][–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏][Email –Ω–∞–π–¥–µ–Ω–æ]
```

## üìà –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã

### –ó–∞–ø—É—Å–∫
```bash
python spider.py
Input site
http://example.com/
```

### –ü—Ä–æ—Ü–µ—Å—Å
```
C:\Users\...\PARSERS\dorkgen\output
–û–±—Ä–∞–±–æ—Ç–∫–∞: http://example.com/
15[3][5]
–û–±—Ä–∞–±–æ—Ç–∫–∞: http://example.com/about/
28[7][8]
–û–±—Ä–∞–±–æ—Ç–∫–∞: http://example.com/contacts/
45[12][15]
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç

#### output/urls.txt
```
http://example.com/
http://example.com/about/
http://example.com/contacts/
http://example.com/about/team/
```

#### output/emails.txt
```
contactForm
emailInput
subscribeEmail
adminEmail
```

## üîç –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ output/
```python
os.path.abspath(__file__).replace(
    os.path.abspath(__file__).split('/')[-1],
    'output/'
)
```

### –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ email –∏–∑ name –∞—Ç—Ä–∏–±—É—Ç–æ–≤
```python
if 'name' in line.split('"')[i]:
    if line.split('"')[i+1] in dork_score:
        pass
    else:
        dork_score.append(line.split('"')[i+1])
        temp2_save.write(line.split('"')[i+1])
```

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π
```python
if '/' in new_line0[i][0]:
    new_line2 = str(site) + str(new_line0[i])
```

### –°—á–µ—Ç—á–∏–∫–∏
- `count` - –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –¥–æ–º–µ–Ω–∞
- `count2` - –ù–∞–π–¥–µ–Ω–Ω—ã–µ email/–∏–º–µ–Ω–∞
- `len(sites_score)` - –í—Å–µ–≥–æ URL

## üí° –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ—Ä–∫–æ–≤
–ù–∞–π–¥–µ–Ω–Ω—ã–µ URL –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–æ—Ä–∫–æ–≤:
```
site:example.com inurl:admin
site:example.com inurl:login
site:example.com inurl:panel
```

### –°–±–æ—Ä –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
Email –∏–∑ name –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Ñ–æ—Ä–º:
```html
<input name="email" />
<input name="contactEmail" />
<input name="adminEmail" />
```

### –ö–∞—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∞–π—Ç–∞
–ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∞–π—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.

## üêõ –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –ü—Ä–æ–±–ª–µ–º–∞: –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª
**–†–µ—à–µ–Ω–∏–µ:** –ù–∞–∂–º–∏—Ç–µ `Ctrl+C` –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ:
```python
max_urls = 1000
if len(sites_score) >= max_urls:
    break
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–∞–ª–æ email –Ω–∞–π–¥–µ–Ω–æ
**–†–µ—à–µ–Ω–∏–µ:** 
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–æ—Ä–º –Ω–∞ —Å–∞–π—Ç–µ
- –†–∞—Å—à–∏—Ä—å—Ç–µ –ø–æ–∏—Å–∫ –Ω–∞ –¥—Ä—É–≥–∏–µ –∞—Ç—Ä–∏–±—É—Ç—ã

### –ü—Ä–æ–±–ª–µ–º–∞: –û–±—Ö–æ–¥ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω
**–†–µ—à–µ–Ω–∏–µ:**
- –î–æ–±–∞–≤—å—Ç–µ –∑–∞–¥–µ—Ä–∂–∫–∏
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ User-Agent

## üí° –£–ª—É—á—à–µ–Ω–∏—è

### 1. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã
```python
max_depth = 3
current_depth = 0

def check(depth):
    if depth >= max_depth:
        return
```

### 2. –ó–∞–¥–µ—Ä–∂–∫–∏
```python
import time
time.sleep(0.1)  # –£–∂–µ –µ—Å—Ç—å 0.001, —É–≤–µ–ª–∏—á—å—Ç–µ
```

### 3. –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ email
```python
import re
email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
emails = re.findall(email_pattern, html)
```

### 4. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
```python
import logging
logging.basicConfig(filename='crawler.log', level=logging.INFO)
```

### 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
```python
try:
    req1 = requests.get(sites_score[x], timeout=10)
except requests.exceptions.RequestException as e:
    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ {sites_score[x]}: {e}")
```

## üîÑ –ú–∏–≥—Ä–∞—Ü–∏—è –Ω–∞ Python 3

```python
# –ë—ã–ª–æ (Python 2)
print "Input site"
site = raw_input()

# –°—Ç–∞–ª–æ (Python 3)
print("Input site")
site = input()
```

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã

### –î–æ–±–∞–≤–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
```python
stats = {
    'total_urls': len(sites_score),
    'internal_urls': count,
    'external_urls': len(sites_score) - count,
    'emails_found': count2,
    'unique_emails': len(set(dork_score))
}

print(json.dumps(stats, indent=2))
```

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
- –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ robots.txt
- –î–æ–±–∞–≤–ª—è–π—Ç–µ –∑–∞–¥–µ—Ä–∂–∫–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑—É–º–Ω—ã–π User-Agent
- –ù–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞–π—Ç–µ —Å–µ—Ä–≤–µ—Ä

### robots.txt
```python
from urllib.robotparser import RobotFileParser

rp = RobotFileParser()
rp.set_url(f"{site}/robots.txt")
rp.read()

if rp.can_fetch("*", url):
    # –ú–æ–∂–Ω–æ –∫—Ä–∞—É–ª–∏—Ç—å
```

## üìù –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ê—É–¥–∏—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å–∞–π—Ç–∞
```bash
python spider.py
Input site
http://mywebsite.com/
# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —Ñ–æ—Ä–º—ã
```

### –°–±–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
```bash
python spider.py
Input site
http://competitor.com/
# –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–∞–π—Ç–∞
```

## üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã

- **basic_web_crawler/** - –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –±–µ–∑ email
- **email_extractor/** - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π email –∫—Ä–∞—É–ª–µ—Ä
- **search_engine_parser/** - –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ—Ä–∫–æ–≤

---

**–ê–≤—Ç–æ—Ä:** Jazis  
**–í–µ—Ä—Å–∏—è:** 1.0  
**Python:** 2.7 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ 3.x)  
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 16 –¥–µ–∫–∞–±—Ä—è 2025
